# Custom vLLM

Builds vLLM inference server on top of base image built here https://github.ibm.com/project-pim/base-images


### Build
```
$ podman build -t <your_registry>/vllm
$
$ podman push <your_registry>/vllm
```
